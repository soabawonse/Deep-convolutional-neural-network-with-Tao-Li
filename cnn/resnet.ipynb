{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "ROOT = \".data\"\n",
    "VALID_RATIO = 0.9\n",
    "BATCH_SIZE = 64\n",
    "DROPOUT = 0.05\n",
    "OUTPUT_CLASSES = 10\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "\n",
    "    def __init__(self, valid_ratio, batch_size):\n",
    "        \n",
    "        \"\"\"Downloads, splits and normalizes the data. Provides dataloaders for training\"\"\"\n",
    "\n",
    "        train_data = datasets.CIFAR10(root=ROOT,\n",
    "                            train=True,\n",
    "                            download=True)\n",
    "        train_data.data = torch.tensor(train_data.data)\n",
    "\n",
    "        channels = train_data.data.split(1, dim=-1)\n",
    "        channel_tensors = [channel.squeeze(-1) for channel in channels]\n",
    "\n",
    "        means = [z.float().mean() / 255 for z in channel_tensors]\n",
    "        stds = [z.float().std() / 255 for z in channel_tensors]\n",
    "\n",
    "        print(f'Calculated mean: {means}')\n",
    "        print(f'Calculated std: {stds}')\n",
    "\n",
    "        train_transforms = transforms.Compose([\n",
    "                            transforms.RandomRotation(10),\n",
    "                            transforms.RandomCrop(32, padding=2),\n",
    "                            transforms.RandomHorizontalFlip(p=0.5),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=means, std=stds)\n",
    "                                      ])\n",
    "\n",
    "        test_transforms = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=means, std=stds)\n",
    "                                            ])\n",
    "\n",
    "        train_data = datasets.CIFAR10(root=ROOT,\n",
    "                                    train=True,\n",
    "                                    download=True,\n",
    "                                    transform=train_transforms)\n",
    "\n",
    "        test_data = datasets.CIFAR10(root=ROOT,\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=test_transforms)\n",
    "        \n",
    "        n_train_examples = int(len(train_data) * valid_ratio)\n",
    "        n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "        train_data, valid_data = data.random_split(train_data,\n",
    "                                                [n_train_examples, n_valid_examples])\n",
    "\n",
    "        valid_data = copy.deepcopy(valid_data)\n",
    "        valid_data.dataset.transform = test_transforms\n",
    "\n",
    "        self.train_loader = data.DataLoader(train_data,\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=batch_size,num_workers=5)\n",
    "\n",
    "        self.valid_loader = data.DataLoader(valid_data,\n",
    "                                        batch_size=batch_size,num_workers=5)\n",
    "        \n",
    "        self.test_loader = data.DataLoader(test_data, shuffle=False, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [17:35<00:00, 161497.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/cifar-10-python.tar.gz to .data\n",
      "Calculated mean: [tensor(0.4914), tensor(0.4822), tensor(0.4465)]\n",
      "Calculated std: [tensor(0.2470), tensor(0.2435), tensor(0.2616)]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "info = Data(VALID_RATIO, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    \"\"\"The Residual block of ResNet models, from the d2l textbook.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1, dp=0.05):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
    "                                   stride=strides)\n",
    "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "        self.dp = nn.Dropout(p=dp)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = self.dp(F.relu(self.bn1(self.conv1(X))))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return self.dp(F.relu(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10, dp=0.1):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.dp = dp\n",
    "        self.lr = lr\n",
    "\n",
    "        self.net = nn.Sequential(self.b1())\n",
    "        for i, b in enumerate(arch):\n",
    "            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def block(self, num_residuals, num_channels, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(num_channels, use_1x1conv=True, strides=2, dp=self.dp))\n",
    "            else:\n",
    "                blk.append(Residual(num_channels, dp=self.dp))\n",
    "        return nn.Sequential(*blk)\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    \n",
    "class ResNet18(ResNet):\n",
    "    def __init__(self, lr=0.1, num_classes=10, dp=0.1):\n",
    "        self.dp = dp\n",
    "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)), lr, num_classes, dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, data, optimizer, criterion, device):\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    def calculate_accuracy(self, y_pred, y):\n",
    "        top_pred = y_pred.argmax(1, keepdim=True)\n",
    "        correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "        acc = correct.float() / y.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def count_parameters(self, model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    def train(self):\n",
    "\n",
    "        iterator = self.data.train_loader\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            y_pred = self.model(x)\n",
    "\n",
    "            loss = self.criterion(y_pred, y)\n",
    "\n",
    "            acc = self.calculate_accuracy(y_pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "    def evaluate(self):\n",
    "\n",
    "        iterator = self.data.valid_loader\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for (x, y) in tqdm(self.iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                y_pred = self.model(x)\n",
    "\n",
    "                loss = self.criterion(y_pred, y)\n",
    "\n",
    "                acc = self.calculate_accuracy(y_pred, y)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    \n",
    "    def epoch_time(start_time, end_time):\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Calculated mean: [tensor(0.4914), tensor(0.4822), tensor(0.4465)]\n",
      "Calculated std: [tensor(0.2470), tensor(0.2435), tensor(0.2616)]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
      "    import torch._dynamo\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/_dynamo/__init__.py\", line 1, in <module>\n",
      "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 43, in <module>\n",
      "    from .output_graph import OutputGraph\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/_dynamo/output_graph.py\", line 34, in <module>\n",
      "    from . import config, logging as torchdynamo_logging, variables\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/_dynamo/variables/__init__.py\", line 49, in <module>\n",
      "    from .torch import TorchHigherOrderOperatorVariable, TorchVariable\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/_dynamo/variables/torch.py\", line 134, in <module>\n",
      "    import transformers\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/transformers/dependency_versions_check.py\", line 17, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/transformers/utils/__init__.py\", line 30, in <module>\n",
      "    from .generic import (\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/transformers/utils/generic.py\", line 33, in <module>\n",
      "    import jax.numpy as jnp\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/jax/__init__.py\", line 35, in <module>\n",
      "    from jax import config as _config_module\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/jax/config.py\", line 17, in <module>\n",
      "    from jax._src.config import config  # noqa: F401\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/jax/_src/config.py\", line 24, in <module>\n",
      "    from jax._src import lib\n",
      "  File \"/Users/luisali/miniconda3/envs/d2l/lib/python3.9/site-packages/jax/_src/lib/__init__.py\", line 84, in <module>\n",
      "    cpu_feature_guard.check_cpu_features()\n",
      "RuntimeError: This version of jaxlib was built using AVX instructions, which your CPU and/or operating system do not support. You may be able work around this issue by building jaxlib from source.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m criterion \u001b[39m=\u001b[39m criterion\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m model(\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39;49m(info\u001b[39m.\u001b[39;49mtrain_loader))[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     17\u001b[0m model\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39mapply(init_cnn)\n\u001b[1;32m     19\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, info, optimizer, criterion, device)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/utils/data/dataloader.py:384\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 384\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1048\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1041\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1048\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1049\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1050\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def init_cnn(module: nn.Module):\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "info = Data(VALID_RATIO, BATCH_SIZE)\n",
    "model = ResNet18(lr=LEARNING_RATE, num_classes=OUTPUT_CLASSES, dp=DROPOUT)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "model(next(iter(info.train_loader))[0].to(device))\n",
    "\n",
    "print(next(iter(info.train_loader))[0])\n",
    "model.net.apply(init_cnn)\n",
    "\n",
    "trainer = Trainer(model, info, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571347bb12034289af47d66248351db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1846057864c44b4684e1795019225d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m trange(EPOCHS, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m----> 7\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      8\u001b[0m     valid_loss, valid_acc \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mevaluate()\n\u001b[1;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m valid_loss \u001b[39m<\u001b[39m best_valid_loss:\n",
      "Cell \u001b[0;32mIn[47], line 41\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(y_pred, y)\n\u001b[1;32m     39\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate_accuracy(y_pred, y)\n\u001b[0;32m---> 41\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = trainer.train()\n",
    "    valid_loss, valid_acc = trainer.evaluate()\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'IMAGENETMODEL.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = trainer.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
