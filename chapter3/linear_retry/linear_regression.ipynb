{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies the update given a set of parameters and a learning \n",
    "# rate lr. essentially a class used advance the parameters in the correct direction\n",
    " \n",
    "class SGD():\n",
    "    \"\"\"Minibatch stochastic gradient descent\"\"\"\n",
    "\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            print(f\"Gradient: {param.grad}\")\n",
    "            param -= self.lr * param.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HouseSale:\n",
    "\n",
    "    def __init__(self, num_features, lr):\n",
    "        self.w = torch.normal(100, 0.01, (num_features, 1), requires_grad=True)\n",
    "        self.b = torch.zeros(1, requires_grad=True)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, X):\n",
    "        return torch.matmul(X, self.w) + self.b\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        return ((y_hat - y) ** 2 / 2).mean()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return SGD([self.w, self.b], self.lr)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        return self.loss(self.forward(batch[0]), batch[1])\n",
    "    \n",
    "    def check(self):\n",
    "        print(\"X train\")\n",
    "        # print(self.x_train)\n",
    "        print(self.x_train.shape)\n",
    "        print(\"Y train\")\n",
    "        # print(self.y_train)\n",
    "        print(self.y_train.shape)\n",
    "        print(\"X val\")\n",
    "        # print(self.x_val)\n",
    "        print(self.x_val.shape)\n",
    "        print(\"Y val\")\n",
    "        # print(self.y_val)\n",
    "        print(self.y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "        data = pd.read_csv('housing.csv')\n",
    "        x = data.loc[:,[\"area\"]]\n",
    "        x = x[:].values\n",
    "        y = data.loc[:,\"price\"]\n",
    "        y = y[:].values\n",
    "        y = y / y.sum()\n",
    "        x = x / x.sum()\n",
    "        self.x_train = torch.tensor(x[0:400], dtype=torch.float32, requires_grad=True)\n",
    "        self.x_val = torch.tensor(x[400:500], dtype=torch.float32, requires_grad=True)\n",
    "        self.y_train = torch.tensor(y[0:400], dtype=torch.float32, requires_grad=True)\n",
    "        self.y_val = torch.tensor(y[400:500], dtype=torch.float32, requires_grad=True)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        iters = self.x_train.shape[0] // self.batch_size\n",
    "        for i in range(iters):\n",
    "            yield [self.x_train[i:i+self.batch_size, :], self.y_train[i:i+self.batch_size].reshape((self.batch_size, 1))]\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        iters = self.x_val.shape[0] // self.batch_size\n",
    "        for i in range(0, iters):\n",
    "            yield [self.x_val[i:i+self.batch_size, :], self.y_val[i:i+ self.batch_size].reshape((self.batch_size, 1))]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04260017350316048\n",
      "Gradient: tensor([[0.0009]])\n",
      "Gradient: tensor([0.2749])\n",
      "Weight: tensor([[100.0044]], requires_grad=True)\n",
      "Bias: tensor([-0.1375], requires_grad=True)\n",
      "Loss: 0.013884807005524635\n",
      "Gradient: tensor([[0.0005]])\n",
      "Gradient: tensor([0.1320])\n",
      "Weight: tensor([[100.0042]], requires_grad=True)\n",
      "Bias: tensor([-0.2035], requires_grad=True)\n",
      "Loss: 0.0070966435596346855\n",
      "Gradient: tensor([[0.0003]])\n",
      "Gradient: tensor([0.0629])\n",
      "Weight: tensor([[100.0040]], requires_grad=True)\n",
      "Bias: tensor([-0.2349], requires_grad=True)\n",
      "Loss: 0.005341439973562956\n",
      "Gradient: tensor([[0.0002]])\n",
      "Gradient: tensor([0.0281])\n",
      "Weight: tensor([[100.0040]], requires_grad=True)\n",
      "Bias: tensor([-0.2490], requires_grad=True)\n",
      "Loss: 0.005242545623332262\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0089])\n",
      "Weight: tensor([[100.0039]], requires_grad=True)\n",
      "Bias: tensor([-0.2534], requires_grad=True)\n",
      "Loss: 0.005292498040944338\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0070])\n",
      "Weight: tensor([[100.0038]], requires_grad=True)\n",
      "Bias: tensor([-0.2569], requires_grad=True)\n",
      "Loss: 0.005291906651109457\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0018])\n",
      "Weight: tensor([[100.0038]], requires_grad=True)\n",
      "Bias: tensor([-0.2578], requires_grad=True)\n",
      "Loss: 0.0052983108907938\n",
      "Gradient: tensor([[9.6505e-05]])\n",
      "Gradient: tensor([-0.0037])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2560], requires_grad=True)\n",
      "Loss: 0.0028581242077052593\n",
      "Gradient: tensor([[1.8675e-05]])\n",
      "Gradient: tensor([-0.0148])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2486], requires_grad=True)\n",
      "Loss: 0.0027674210723489523\n",
      "Gradient: tensor([[3.6055e-05]])\n",
      "Gradient: tensor([-0.0077])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2447], requires_grad=True)\n",
      "Loss: 0.002765424782410264\n",
      "Gradient: tensor([[4.4788e-05]])\n",
      "Gradient: tensor([-0.0042])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2426], requires_grad=True)\n",
      "Loss: 0.0015159596223384142\n",
      "Gradient: tensor([[5.3001e-08]])\n",
      "Gradient: tensor([-0.0123])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2365], requires_grad=True)\n",
      "Loss: 0.0014441637322306633\n",
      "Gradient: tensor([[1.8452e-05]])\n",
      "Gradient: tensor([-0.0043])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2343], requires_grad=True)\n",
      "Loss: 0.0015377721283584833\n",
      "Gradient: tensor([[1.8561e-05]])\n",
      "Gradient: tensor([-0.0051])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2317], requires_grad=True)\n",
      "Loss: 0.0012348968302831054\n",
      "Gradient: tensor([[2.9021e-05]])\n",
      "Gradient: tensor([0.0018])\n",
      "Weight: tensor([[100.0037]], requires_grad=True)\n",
      "Bias: tensor([-0.2326], requires_grad=True)\n",
      "Loss: 0.0011917490046471357\n",
      "Gradient: tensor([[2.2015e-05]])\n",
      "Gradient: tensor([-0.0008])\n",
      "Weight: tensor([[100.0036]], requires_grad=True)\n",
      "Bias: tensor([-0.2323], requires_grad=True)\n",
      "Loss: 0.0011843383545055985\n",
      "Gradient: tensor([[2.7019e-05]])\n",
      "Gradient: tensor([0.0014])\n",
      "Weight: tensor([[100.0036]], requires_grad=True)\n",
      "Bias: tensor([-0.2330], requires_grad=True)\n",
      "Loss: 0.0012067906791344285\n",
      "Gradient: tensor([[2.9561e-05]])\n",
      "Gradient: tensor([0.0023])\n",
      "Weight: tensor([[100.0036]], requires_grad=True)\n",
      "Bias: tensor([-0.2341], requires_grad=True)\n",
      "Loss: 0.0012724337866529822\n",
      "Gradient: tensor([[3.0316e-05]])\n",
      "Gradient: tensor([0.0021])\n",
      "Weight: tensor([[100.0036]], requires_grad=True)\n",
      "Bias: tensor([-0.2351], requires_grad=True)\n",
      "Loss: 0.0011463466798886657\n",
      "Gradient: tensor([[3.1357e-05]])\n",
      "Gradient: tensor([0.0035])\n",
      "Weight: tensor([[100.0036]], requires_grad=True)\n",
      "Bias: tensor([-0.2369], requires_grad=True)\n",
      "Loss: 0.005524883978068829\n",
      "Gradient: tensor([[0.0002]])\n",
      "Gradient: tensor([0.0380])\n",
      "Weight: tensor([[100.0035]], requires_grad=True)\n",
      "Bias: tensor([-0.2559], requires_grad=True)\n",
      "Loss: 0.005259835161268711\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0136])\n",
      "Weight: tensor([[100.0034]], requires_grad=True)\n",
      "Bias: tensor([-0.2627], requires_grad=True)\n",
      "Loss: 0.0051267510280013084\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0036])\n",
      "Weight: tensor([[100.0034]], requires_grad=True)\n",
      "Bias: tensor([-0.2645], requires_grad=True)\n",
      "Loss: 0.004947630688548088\n",
      "Gradient: tensor([[9.4988e-05]])\n",
      "Gradient: tensor([-0.0015])\n",
      "Weight: tensor([[100.0033]], requires_grad=True)\n",
      "Bias: tensor([-0.2638], requires_grad=True)\n",
      "Loss: 0.005220573395490646\n",
      "Gradient: tensor([[8.8675e-05]])\n",
      "Gradient: tensor([-0.0059])\n",
      "Weight: tensor([[100.0033]], requires_grad=True)\n",
      "Bias: tensor([-0.2608], requires_grad=True)\n",
      "Loss: 0.005268354434520006\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0004])\n",
      "Weight: tensor([[100.0032]], requires_grad=True)\n",
      "Bias: tensor([-0.2606], requires_grad=True)\n",
      "Loss: 0.005291988141834736\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0019])\n",
      "Weight: tensor([[100.0032]], requires_grad=True)\n",
      "Bias: tensor([-0.2597], requires_grad=True)\n",
      "Loss: 0.00530672911554575\n",
      "Gradient: tensor([[9.1736e-05]])\n",
      "Gradient: tensor([-0.0055])\n",
      "Weight: tensor([[100.0031]], requires_grad=True)\n",
      "Bias: tensor([-0.2569], requires_grad=True)\n",
      "Loss: 0.0028722540009766817\n",
      "Gradient: tensor([[1.6412e-05]])\n",
      "Gradient: tensor([-0.0158])\n",
      "Weight: tensor([[100.0031]], requires_grad=True)\n",
      "Bias: tensor([-0.2490], requires_grad=True)\n",
      "Loss: 0.0027710385620594025\n",
      "Gradient: tensor([[3.4924e-05]])\n",
      "Gradient: tensor([-0.0081])\n",
      "Weight: tensor([[100.0031]], requires_grad=True)\n",
      "Bias: tensor([-0.2450], requires_grad=True)\n",
      "Loss: 0.0027664010412991047\n",
      "Gradient: tensor([[4.4224e-05]])\n",
      "Gradient: tensor([-0.0045])\n",
      "Weight: tensor([[100.0031]], requires_grad=True)\n",
      "Bias: tensor([-0.2427], requires_grad=True)\n",
      "Loss: 0.0015173699939623475\n",
      "Gradient: tensor([[-2.1731e-07]])\n",
      "Gradient: tensor([-0.0124])\n",
      "Weight: tensor([[100.0031]], requires_grad=True)\n",
      "Bias: tensor([-0.2365], requires_grad=True)\n",
      "Loss: 0.0014443990075960755\n",
      "Gradient: tensor([[1.8316e-05]])\n",
      "Gradient: tensor([-0.0044])\n",
      "Weight: tensor([[100.0031]], requires_grad=True)\n",
      "Bias: tensor([-0.2343], requires_grad=True)\n",
      "Loss: 0.0015379020478576422\n",
      "Gradient: tensor([[1.8493e-05]])\n",
      "Gradient: tensor([-0.0052])\n",
      "Weight: tensor([[100.0031]], requires_grad=True)\n",
      "Bias: tensor([-0.2317], requires_grad=True)\n",
      "Loss: 0.001234855386428535\n",
      "Gradient: tensor([[2.8987e-05]])\n",
      "Gradient: tensor([0.0018])\n",
      "Weight: tensor([[100.0030]], requires_grad=True)\n",
      "Bias: tensor([-0.2326], requires_grad=True)\n",
      "Loss: 0.001191740040667355\n",
      "Gradient: tensor([[2.1998e-05]])\n",
      "Gradient: tensor([-0.0008])\n",
      "Weight: tensor([[100.0030]], requires_grad=True)\n",
      "Bias: tensor([-0.2323], requires_grad=True)\n",
      "Loss: 0.0011843189131468534\n",
      "Gradient: tensor([[2.7010e-05]])\n",
      "Gradient: tensor([0.0014])\n",
      "Weight: tensor([[100.0030]], requires_grad=True)\n",
      "Bias: tensor([-0.2330], requires_grad=True)\n",
      "Loss: 0.001206772169098258\n",
      "Gradient: tensor([[2.9557e-05]])\n",
      "Gradient: tensor([0.0023])\n",
      "Weight: tensor([[100.0030]], requires_grad=True)\n",
      "Bias: tensor([-0.2341], requires_grad=True)\n",
      "Loss: 0.0012724166736006737\n",
      "Gradient: tensor([[3.0314e-05]])\n",
      "Gradient: tensor([0.0021])\n",
      "Weight: tensor([[100.0030]], requires_grad=True)\n",
      "Bias: tensor([-0.2351], requires_grad=True)\n",
      "Loss: 0.0011463308474048972\n",
      "Gradient: tensor([[3.1356e-05]])\n",
      "Gradient: tensor([0.0035])\n",
      "Weight: tensor([[100.0030]], requires_grad=True)\n",
      "Bias: tensor([-0.2369], requires_grad=True)\n",
      "Loss: 0.005524808075278997\n",
      "Gradient: tensor([[0.0002]])\n",
      "Gradient: tensor([0.0380])\n",
      "Weight: tensor([[100.0029]], requires_grad=True)\n",
      "Bias: tensor([-0.2559], requires_grad=True)\n",
      "Loss: 0.005259769968688488\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0136])\n",
      "Weight: tensor([[100.0028]], requires_grad=True)\n",
      "Bias: tensor([-0.2627], requires_grad=True)\n",
      "Loss: 0.005126688629388809\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0036])\n",
      "Weight: tensor([[100.0028]], requires_grad=True)\n",
      "Bias: tensor([-0.2645], requires_grad=True)\n",
      "Loss: 0.004947570152580738\n",
      "Gradient: tensor([[9.4988e-05]])\n",
      "Gradient: tensor([-0.0015])\n",
      "Weight: tensor([[100.0027]], requires_grad=True)\n",
      "Bias: tensor([-0.2638], requires_grad=True)\n",
      "Loss: 0.005220509134232998\n",
      "Gradient: tensor([[8.8674e-05]])\n",
      "Gradient: tensor([-0.0059])\n",
      "Weight: tensor([[100.0027]], requires_grad=True)\n",
      "Bias: tensor([-0.2608], requires_grad=True)\n",
      "Loss: 0.00526828970760107\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0004])\n",
      "Weight: tensor([[100.0026]], requires_grad=True)\n",
      "Bias: tensor([-0.2606], requires_grad=True)\n",
      "Loss: 0.005291923880577087\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0019])\n",
      "Weight: tensor([[100.0026]], requires_grad=True)\n",
      "Bias: tensor([-0.2597], requires_grad=True)\n",
      "Loss: 0.005306663922965527\n",
      "Gradient: tensor([[9.1735e-05]])\n",
      "Gradient: tensor([-0.0055])\n",
      "Weight: tensor([[100.0025]], requires_grad=True)\n",
      "Bias: tensor([-0.2569], requires_grad=True)\n",
      "Loss: 0.00287221884354949\n",
      "Gradient: tensor([[1.6411e-05]])\n",
      "Gradient: tensor([-0.0158])\n",
      "Weight: tensor([[100.0025]], requires_grad=True)\n",
      "Bias: tensor([-0.2490], requires_grad=True)\n",
      "Loss: 0.0027710050344467163\n",
      "Gradient: tensor([[3.4924e-05]])\n",
      "Gradient: tensor([-0.0081])\n",
      "Weight: tensor([[100.0025]], requires_grad=True)\n",
      "Bias: tensor([-0.2450], requires_grad=True)\n",
      "Loss: 0.0027663675136864185\n",
      "Gradient: tensor([[4.4223e-05]])\n",
      "Gradient: tensor([-0.0045])\n",
      "Weight: tensor([[100.0025]], requires_grad=True)\n",
      "Bias: tensor([-0.2427], requires_grad=True)\n",
      "Loss: 0.001517351483926177\n",
      "Gradient: tensor([[-2.1730e-07]])\n",
      "Gradient: tensor([-0.0124])\n",
      "Weight: tensor([[100.0025]], requires_grad=True)\n",
      "Bias: tensor([-0.2365], requires_grad=True)\n",
      "Loss: 0.0014443814288824797\n",
      "Gradient: tensor([[1.8316e-05]])\n",
      "Gradient: tensor([-0.0044])\n",
      "Weight: tensor([[100.0025]], requires_grad=True)\n",
      "Bias: tensor([-0.2343], requires_grad=True)\n",
      "Loss: 0.001537883304990828\n",
      "Gradient: tensor([[1.8493e-05]])\n",
      "Gradient: tensor([-0.0052])\n",
      "Weight: tensor([[100.0024]], requires_grad=True)\n",
      "Bias: tensor([-0.2317], requires_grad=True)\n",
      "Loss: 0.0012348402524366975\n",
      "Gradient: tensor([[2.8986e-05]])\n",
      "Gradient: tensor([0.0018])\n",
      "Weight: tensor([[100.0024]], requires_grad=True)\n",
      "Bias: tensor([-0.2326], requires_grad=True)\n",
      "Loss: 0.0011917257215827703\n",
      "Gradient: tensor([[2.1998e-05]])\n",
      "Gradient: tensor([-0.0008])\n",
      "Weight: tensor([[100.0024]], requires_grad=True)\n",
      "Bias: tensor([-0.2323], requires_grad=True)\n",
      "Loss: 0.0011843042448163033\n",
      "Gradient: tensor([[2.7010e-05]])\n",
      "Gradient: tensor([0.0014])\n",
      "Weight: tensor([[100.0024]], requires_grad=True)\n",
      "Bias: tensor([-0.2330], requires_grad=True)\n",
      "Loss: 0.0012067571515217423\n",
      "Gradient: tensor([[2.9557e-05]])\n",
      "Gradient: tensor([0.0023])\n",
      "Weight: tensor([[100.0024]], requires_grad=True)\n",
      "Bias: tensor([-0.2341], requires_grad=True)\n",
      "Loss: 0.0012724008411169052\n",
      "Gradient: tensor([[3.0314e-05]])\n",
      "Gradient: tensor([0.0021])\n",
      "Weight: tensor([[100.0024]], requires_grad=True)\n",
      "Bias: tensor([-0.2351], requires_grad=True)\n",
      "Loss: 0.0011463169939815998\n",
      "Gradient: tensor([[3.1356e-05]])\n",
      "Gradient: tensor([0.0035])\n",
      "Weight: tensor([[100.0024]], requires_grad=True)\n",
      "Bias: tensor([-0.2369], requires_grad=True)\n",
      "Loss: 0.005524740554392338\n",
      "Gradient: tensor([[0.0002]])\n",
      "Gradient: tensor([0.0380])\n",
      "Weight: tensor([[100.0023]], requires_grad=True)\n",
      "Bias: tensor([-0.2559], requires_grad=True)\n",
      "Loss: 0.005259705241769552\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0136])\n",
      "Weight: tensor([[100.0022]], requires_grad=True)\n",
      "Bias: tensor([-0.2627], requires_grad=True)\n",
      "Loss: 0.00512662623077631\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0036])\n",
      "Weight: tensor([[100.0021]], requires_grad=True)\n",
      "Bias: tensor([-0.2645], requires_grad=True)\n",
      "Loss: 0.004947510082274675\n",
      "Gradient: tensor([[9.4987e-05]])\n",
      "Gradient: tensor([-0.0015])\n",
      "Weight: tensor([[100.0021]], requires_grad=True)\n",
      "Bias: tensor([-0.2638], requires_grad=True)\n",
      "Loss: 0.005220444872975349\n",
      "Gradient: tensor([[8.8674e-05]])\n",
      "Gradient: tensor([-0.0059])\n",
      "Weight: tensor([[100.0021]], requires_grad=True)\n",
      "Bias: tensor([-0.2608], requires_grad=True)\n",
      "Loss: 0.005268225446343422\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0004])\n",
      "Weight: tensor([[100.0020]], requires_grad=True)\n",
      "Bias: tensor([-0.2606], requires_grad=True)\n",
      "Loss: 0.005291859619319439\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0019])\n",
      "Weight: tensor([[100.0019]], requires_grad=True)\n",
      "Bias: tensor([-0.2597], requires_grad=True)\n",
      "Loss: 0.0053065987303853035\n",
      "Gradient: tensor([[9.1735e-05]])\n",
      "Gradient: tensor([-0.0055])\n",
      "Weight: tensor([[100.0019]], requires_grad=True)\n",
      "Bias: tensor([-0.2569], requires_grad=True)\n",
      "Loss: 0.0028721834532916546\n",
      "Gradient: tensor([[1.6411e-05]])\n",
      "Gradient: tensor([-0.0158])\n",
      "Weight: tensor([[100.0019]], requires_grad=True)\n",
      "Bias: tensor([-0.2490], requires_grad=True)\n",
      "Loss: 0.0027709712740033865\n",
      "Gradient: tensor([[3.4924e-05]])\n",
      "Gradient: tensor([-0.0081])\n",
      "Weight: tensor([[100.0019]], requires_grad=True)\n",
      "Bias: tensor([-0.2450], requires_grad=True)\n",
      "Loss: 0.0027663332875818014\n",
      "Gradient: tensor([[4.4223e-05]])\n",
      "Gradient: tensor([-0.0045])\n",
      "Weight: tensor([[100.0019]], requires_grad=True)\n",
      "Bias: tensor([-0.2427], requires_grad=True)\n",
      "Loss: 0.0015173329738900065\n",
      "Gradient: tensor([[-2.1728e-07]])\n",
      "Gradient: tensor([-0.0124])\n",
      "Weight: tensor([[100.0019]], requires_grad=True)\n",
      "Bias: tensor([-0.2365], requires_grad=True)\n",
      "Loss: 0.001444363733753562\n",
      "Gradient: tensor([[1.8316e-05]])\n",
      "Gradient: tensor([-0.0044])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2343], requires_grad=True)\n",
      "Loss: 0.001537864562124014\n",
      "Gradient: tensor([[1.8493e-05]])\n",
      "Gradient: tensor([-0.0052])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2317], requires_grad=True)\n",
      "Loss: 0.00123482511844486\n",
      "Gradient: tensor([[2.8986e-05]])\n",
      "Gradient: tensor([0.0018])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2326], requires_grad=True)\n",
      "Loss: 0.001191711169667542\n",
      "Gradient: tensor([[2.1998e-05]])\n",
      "Gradient: tensor([-0.0008])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2323], requires_grad=True)\n",
      "Loss: 0.0011842900421470404\n",
      "Gradient: tensor([[2.7010e-05]])\n",
      "Gradient: tensor([0.0014])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2330], requires_grad=True)\n",
      "Loss: 0.0012067423667758703\n",
      "Gradient: tensor([[2.9557e-05]])\n",
      "Gradient: tensor([0.0023])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2341], requires_grad=True)\n",
      "Loss: 0.0012723853578791022\n",
      "Gradient: tensor([[3.0313e-05]])\n",
      "Gradient: tensor([0.0021])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2351], requires_grad=True)\n",
      "Loss: 0.0011463032569736242\n",
      "Gradient: tensor([[3.1356e-05]])\n",
      "Gradient: tensor([0.0035])\n",
      "Weight: tensor([[100.0018]], requires_grad=True)\n",
      "Bias: tensor([-0.2369], requires_grad=True)\n",
      "Loss: 0.005524672567844391\n",
      "Gradient: tensor([[0.0002]])\n",
      "Gradient: tensor([0.0380])\n",
      "Weight: tensor([[100.0017]], requires_grad=True)\n",
      "Bias: tensor([-0.2559], requires_grad=True)\n",
      "Loss: 0.0052596405148506165\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0136])\n",
      "Weight: tensor([[100.0016]], requires_grad=True)\n",
      "Bias: tensor([-0.2627], requires_grad=True)\n",
      "Loss: 0.005126562900841236\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([0.0036])\n",
      "Weight: tensor([[100.0015]], requires_grad=True)\n",
      "Bias: tensor([-0.2645], requires_grad=True)\n",
      "Loss: 0.004947450011968613\n",
      "Gradient: tensor([[9.4987e-05]])\n",
      "Gradient: tensor([-0.0015])\n",
      "Weight: tensor([[100.0015]], requires_grad=True)\n",
      "Bias: tensor([-0.2638], requires_grad=True)\n",
      "Loss: 0.005220381543040276\n",
      "Gradient: tensor([[8.8673e-05]])\n",
      "Gradient: tensor([-0.0059])\n",
      "Weight: tensor([[100.0014]], requires_grad=True)\n",
      "Bias: tensor([-0.2608], requires_grad=True)\n",
      "Loss: 0.0052681611850857735\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0004])\n",
      "Weight: tensor([[100.0014]], requires_grad=True)\n",
      "Bias: tensor([-0.2606], requires_grad=True)\n",
      "Loss: 0.005291794892400503\n",
      "Gradient: tensor([[0.0001]])\n",
      "Gradient: tensor([-0.0019])\n",
      "Weight: tensor([[100.0013]], requires_grad=True)\n",
      "Bias: tensor([-0.2596], requires_grad=True)\n",
      "Loss: 0.00530653540045023\n",
      "Gradient: tensor([[9.1734e-05]])\n",
      "Gradient: tensor([-0.0055])\n",
      "Weight: tensor([[100.0013]], requires_grad=True)\n",
      "Bias: tensor([-0.2569], requires_grad=True)\n",
      "Loss: 0.002872148994356394\n",
      "Gradient: tensor([[1.6411e-05]])\n",
      "Gradient: tensor([-0.0158])\n",
      "Weight: tensor([[100.0013]], requires_grad=True)\n",
      "Bias: tensor([-0.2490], requires_grad=True)\n",
      "Loss: 0.0027709370478987694\n",
      "Gradient: tensor([[3.4924e-05]])\n",
      "Gradient: tensor([-0.0081])\n",
      "Weight: tensor([[100.0013]], requires_grad=True)\n",
      "Bias: tensor([-0.2449], requires_grad=True)\n",
      "Loss: 0.0027662995271384716\n",
      "Gradient: tensor([[4.4223e-05]])\n",
      "Gradient: tensor([-0.0045])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2427], requires_grad=True)\n",
      "Loss: 0.0015173143474385142\n",
      "Gradient: tensor([[-2.1728e-07]])\n",
      "Gradient: tensor([-0.0124])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2365], requires_grad=True)\n",
      "Loss: 0.001444346155039966\n",
      "Gradient: tensor([[1.8316e-05]])\n",
      "Gradient: tensor([-0.0044])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2343], requires_grad=True)\n",
      "Loss: 0.0015378459356725216\n",
      "Gradient: tensor([[1.8493e-05]])\n",
      "Gradient: tensor([-0.0052])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2317], requires_grad=True)\n",
      "Loss: 0.0012348101008683443\n",
      "Gradient: tensor([[2.8986e-05]])\n",
      "Gradient: tensor([0.0018])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2326], requires_grad=True)\n",
      "Loss: 0.0011916965013369918\n",
      "Gradient: tensor([[2.1998e-05]])\n",
      "Gradient: tensor([-0.0008])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2323], requires_grad=True)\n",
      "Loss: 0.0011842756066471338\n",
      "Gradient: tensor([[2.7009e-05]])\n",
      "Gradient: tensor([0.0014])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2330], requires_grad=True)\n",
      "Loss: 0.0012067274656146765\n",
      "Gradient: tensor([[2.9556e-05]])\n",
      "Gradient: tensor([0.0023])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2341], requires_grad=True)\n",
      "Loss: 0.0012723698746412992\n",
      "Gradient: tensor([[3.0313e-05]])\n",
      "Gradient: tensor([0.0021])\n",
      "Weight: tensor([[100.0012]], requires_grad=True)\n",
      "Bias: tensor([-0.2351], requires_grad=True)\n",
      "Loss: 0.0011462890543043613\n",
      "Gradient: tensor([[3.1355e-05]])\n",
      "Gradient: tensor([0.0035])\n",
      "Weight: tensor([[100.0011]], requires_grad=True)\n",
      "Bias: tensor([-0.2369], requires_grad=True)\n",
      "Trained Weight: tensor([[100.0011]], requires_grad=True)\n",
      "Trained Bias: tensor([-0.2369], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = HouseSale(1, 0.5)\n",
    "data = Data(20)\n",
    "epochs = 5\n",
    "gradient_clip_val = 0\n",
    "sgd = model.configure_optimizers()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for batch in data.train_dataloader():\n",
    "        loss = model.training_step(batch)\n",
    "        print(f\"Loss: {loss}\")\n",
    "        sgd.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "            print(f\"Weight: {model.w}\")\n",
    "            print(f\"Bias: {model.b}\")\n",
    "print(f\"Trained Weight: {model.w}\")\n",
    "print(f\"Trained Bias: {model.b}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
